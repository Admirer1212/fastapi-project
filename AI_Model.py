# -- coding: utf-8 --
"""Gluu.ipynb
Automatically generated by Colab.
Original file is located at
 https://colab.research.google.com/drive/1jy2y3IU8y51I3Jr0RvQcYuYs7YGDjTYJ
"""
# mount your Google Drive files
from google.colab import drive
drive.mount('/content/drive')
# Transformers provides thousands of pretrained models to perform tasks on different 
modalities such as text, vision, and audio.
!pip install transformers
# Import nessessary libraries
from transformers import CLIPProcessor, CLIPModel
import torch
# get CLIP pre-trained model
model = CLIPModel.from_pretrained("laion/CLIP-ViT-H-14-laion2B-s32B-b79K")
processor = CLIPProcessor.from_pretrained("laion/CLIP-ViT-H-14-laion2B-s32B-b79K") # a 
wrapper for input data preprocessing. It includes both encoding the text using tokenizer and 
preparing the images.
# For image displaying
!pip install Pillow
"""### Types test
Types from website:
1. Dress Shoes
2. Loafer
3. Boots (Ankle & Knee High)
4. High Heels & Stilettos
5. Sandals
6. Runners
Types for classification from AI Model
1. Dress Shoes
2. Loafer
3. Boots (Ankle)
4. Boots (Knee High)
5. High Heels & Stilettos
6. Sandals
7. Runners
"""
# Import libraries
15
from PIL import Image
from transformers import pipeline
import os
from PIL import Image
def image_grid(imgs, cols):
 # Calculate the number of rows needed
 rows = (len(imgs) + cols - 1) // cols
 # Get the width and height of the first image (assuming all images are the same size)
 w, h = imgs[0].size
 # Create a new blank image with the appropriate size to fit all images in the grid
 grid = Image.new('RGB', size=(colsw, rowsh))
 # Iterate over the list of images and paste each one into the grid
 for i, img in enumerate(imgs):
 # Calculate the position where the current image should be pasted
 x = (i % cols) w # Column position
 y = (i // cols) h # Row position
 # Paste the image at the calculated position
 grid.paste(img, box=(x, y))
 # Return the final grid image
 return grid
# Local directory containing the images
image_folder = '/content/drive/MyDrive/Colab_Notebooks/Gluu/datasets/test/background'
# List of image filenames in the local directory
image_filenames = [
 'Boots.jpeg',
 'Dress_shoes.jpeg',
 'High_Heels.jpeg',
 'Loafer.jpeg',
 'Runners.jpeg',
 'Sandals.jpg',
 'Stilettos.jpeg'
]
# Append the images together
images = []
for filename in image_filenames:
 img_path = os.path.join(image_folder, filename)
 images.append(Image.open(img_path))
grid = image_grid(images, cols=3)
grid.show() # Use .show() for displaying the image grid
# List of class names for different types of shoes
classes = [
 'Dress Shoes', 'Loafer', 'Boots (Ankle)', 'Boots (Knee High)',
 'High Heels', 'Stilettos', 'Sandals', 'Runners of shoes'
]
16
# Process the text (class names) and images into tensors suitable for the model
inputs = processor(
 text=classes, # List of class names
 images=images, # List of images
 return_tensors="pt", # Return PyTorch tensors
 padding=True, # Pad the inputs to the same length
 do_convert_rgb=False # Assume images are already in RGB format
)
# Pass the processed inputs through the model to get the outputs
outputs = model(inputs)
# Extract the logits for image-text similarity
logits_per_image = outputs.logits_per_image
# Apply softmax to the logits to get probabilities for each class
probs = logits_per_image.softmax(dim=1)
# 'probs' now contains the probabilities of each image belonging to each class
import matplotlib.pyplot as plt
# Create a figure with specified size (width, height)
fig = plt.figure(figsize=(8, 20))
# Loop over each image and its corresponding probabilities
for idx in range(len(images)):
 # Display the original image
 fig.add_subplot(len(images), 2, 2(idx+1)-1)
 plt.imshow(images[idx]) # Show the image
 plt.xticks([]) # Remove x-axis ticks
 plt.yticks([]) # Remove y-axis ticks
 # Display the probabilities as a horizontal bar chart
 fig.add_subplot(len(images), 2, 2(idx+1))
 plt.barh(range(len(probs[0].detach().numpy())), probs[idx].detach().numpy(), 
tick_label=classes)
 plt.xlim(0, 1.0) # Set x-axis limits to range from 0 to 1
 # Adjust subplot parameters for spacing
 plt.subplots_adjust(left=0.1, # Adjust space to the left
 bottom=0.1, # Adjust space at the bottom
 right=0.9, # Adjust space to the right
 top=0.9, # Adjust space at the top
 wspace=0.2, # Adjust horizontal space between subplots
 hspace=0.8) # Adjust vertical space between subplots
# Display the figure with all subplots
plt.show()
"""### Materials test"""
# List of material classes
17
classes = [
 'Leather', 'Rubber', 'Textiles', 'Synthetics', 'Braided',
 'Cork', 'Nylon', 'Neoprene', 'Silk', 'Velvet', 'Foam'
]
# Process the text (material classes) and images into tensors suitable for the model
inputs = processor(
 text=classes, # List of material classes
 images=images, # List of images to classify
 return_tensors="pt", # Convert inputs to PyTorch tensors
 padding=True, # Pad the inputs to the same length
 do_convert_rgb=False # Assume images are already in RGB format
)
# Pass the processed inputs through the model to get the outputs
outputs = model(inputs)
# Extract the logits for image-text similarity from the model outputs
logits_per_image = outputs.logits_per_image
# Apply softmax to the logits to get probabilities for each material class
probs = logits_per_image.softmax(dim=1)
# Import Matplotlib for visualization
import matplotlib.pyplot as plt
# Create a figure for plotting with specified size (width, height)
fig = plt.figure(figsize=(8, 20))
# Loop over each image and its corresponding probabilities
for idx in range(len(images)):
 # Display the original image
 fig.add_subplot(len(images), 2, 2(idx+1)-1) # Add subplot for the image
 plt.imshow(images[idx]) # Show the image
 plt.xticks([]) # Remove x-axis ticks
 plt.yticks([]) # Remove y-axis ticks
 # Display the probabilities as a horizontal bar chart
 fig.add_subplot(len(images), 2, 2(idx+1)) # Add subplot for the bar chart
 plt.barh(range(len(probs[0].detach().numpy())), probs[idx].detach().numpy(), 
tick_label=classes) # Create a horizontal bar chart
 plt.xlim(0, 1.0) # Set x-axis limits to range from 0 to 1
 # Adjust subplot parameters for spacing
 plt.subplots_adjust(
 left=0.1, # Adjust space to the left
 bottom=0.1, # Adjust space at the bottom
 right=0.9, # Adjust space to the right
 top=0.9, # Adjust space at the top
 wspace=0.2, # Adjust horizontal space between subplots
 hspace=0.8 # Adjust vertical space between subplots
 )
# Display the figure with all subplots
plt.show()

import matplotlib.pyplot as plt
# Create a figure for plotting with specified size (width, height)
fig = plt.figure(figsize=(8, 20))
# Loop over each image and its corresponding probabilities
for idx in range(len(images)):
 # Display the original image
 fig.add_subplot(len(images), 2, 2(idx+1)-1) # Add a subplot for the image
 plt.imshow(images[idx]) # Show the image
 plt.xticks([]) # Remove x-axis ticks for a cleaner look
 plt.yticks([]) # Remove y-axis ticks for a cleaner look
 # Display the probabilities as a horizontal bar chart
 fig.add_subplot(len(images), 2, 2(idx+1)) # Add a subplot for the bar chart
 plt.barh(range(len(probs[0].detach().numpy())), probs[idx].detach().numpy(), 
tick_label=classes) # Create a horizontal bar chart
 plt.xlim(0, 1.0) # Set x-axis limits to range from 0 to 1, as probabilities range between 0 and 
1
 # Adjust subplot parameters for spacing
 plt.subplots_adjust(left=0.1, # Adjust space to the left
 bottom=0.1, # Adjust space at the bottom
 right=0.9, # Adjust space to the right
 top=0.9, # Adjust space at the top
 wspace=0.2, # Adjust horizontal space between subplots
 hspace=0.8) # Adjust vertical space between subplots
# Display the figure with all subplots
plt.show()
"""### Damage test:
Reference: https://www.v-trust.com/en/blog/top-10-shoe-defects-every-buyer-should-know
"""
# Import necessary libraries
from PIL import Image
from transformers import pipeline
import os
# Local directory containing the images
image_folder = '/content/drive/MyDrive/Colab_Notebooks/Gluu/datasets/test/Damage'
# List of image filenames in the local directory
image_filenames = [
 'Broken_stitches.jpeg', # Filename of the image showing broken stitches
 'dirty.jpeg', # Filename of the image showing a dirty item
 'Leather_faded.jpeg', # Filename of the image showing faded leather
 'Opened_seam.jpeg', # Filename of the image showing an opened seam
 'Slanted_heel.jpeg', # Filename of the image showing a slanted heel
 'Sole_not_flat.jpeg', # Filename of the image showing a sole that is not flat
 'tears.jpeg', # Filename of the image showing tears
 'Weak_cementing.jpeg', # Filename of the image showing weak cementing

 'Weak_cementing1.jpeg', # Another filename of the image showing weak cementing
 'wrinkles.jpeg', # Filename of the image showing wrinkles
]
# Initialize an empty list to store the images
images = []
for filename in image_filenames:
 # Construct the full path to the image file
 img_path = os.path.join(image_folder, filename)
 # Open the image file and append it to the images list
 images.append(Image.open(img_path))
# Function to create an image grid (this should be defined or imported earlier in the script)
def image_grid(imgs, cols):
 # Calculate the number of rows required
 rows = (len(imgs) + cols - 1) // cols
 # Get the size of the first image (assuming all images are the same size)
 w, h = imgs[0].size
 # Create a new blank image with a size to fit all images in a grid
 grid = Image.new('RGB', size=(colsw, rowsh))
 # Loop through each image and paste it into the grid
 for i, img in enumerate(imgs):
 # Calculate the position where the image should be pasted
 grid.paste(img, box=(i % cols w, i // cols h))
 # Return the combined image grid
 return grid
# Create an image grid with the specified number of columns
grid = image_grid(images, cols=3)
# Display the image grid
grid.show() # Use .show() for displaying the image grid
# Define the list of classes (labels) corresponding to different types of damage
classes = [
 'Broken stitches',
 'Opened seam',
 'Slanted heel',
 'Sole not flat',
 'Peeling leather/tears',
 'Weak cementing',
 'wrinkles',
 'dirty shoes',
 'Leather Faded'
]
# Process the text (class labels) and images to create the inputs for the model
inputs = processor(
 text=classes, # List of class labels
 images=images, # List of images to be classified
 return_tensors="pt", # Return the data as PyTorch tensors
 padding=True, # Pad the inputs to the same length
 do_convert_rgb=False # Do not convert images to RGB (assuming they are already in 
RGB format)
)
# Pass the inputs through the model to get the outputs
outputs = model(inputs)
# Extract the logits for image-text similarity scores
logits_per_image = outputs.logits_per_image # This is the image-text similarity score
# Apply softmax to the logits to get the probabilities for each class
probs = logits_per_image.softmax(dim=1) # Take the softmax to get the label probabilities
# Get the highest scoring label for each image
predicted_labels = torch.argmax(probs, dim=1)
import matplotlib.pyplot as plt
# Create a figure for plotting with specified size (width, height)
fig = plt.figure(figsize=(8, 20))
# Iterate over each image and its corresponding probabilities
for idx in range(len(images)):
 # Show the original image
 fig.add_subplot(len(images), 2, 2(idx+1)-1)
 plt.imshow(images[idx]) # Display the image
 plt.xticks([]) # Remove x-axis ticks for a cleaner look
 plt.yticks([]) # Remove y-axis ticks for a cleaner look
 # Show the predicted probabilities as a horizontal bar chart
 fig.add_subplot(len(images), 2, 2(idx+1))
 plt.barh(range(len(probs[0].detach().numpy())), probs[idx].detach().numpy(), 
tick_label=classes) # Create a horizontal bar chart
 plt.xlim(0, 1.0) # Set x-axis limits to range from 0 to 1, as probabilities range between 0 and 
1
 # Adjust subplot parameters for spacing
 plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.8)
# Display the figure with all subplots
plt.show()
"""### Point to craftperson
1. Heel Repair -> Category with Heel & Slanted Heels
2. Half Sole -> Weak cementing
3. Full sole -> Weak cementing
4. Patch & Sweing Repair -> Broken stitches & Opened seam
5. Hardware Repair -> Sole not flat, wrinkles
6. Insole Repair
7. Internet Heal or Linear Repair
8. Leather Care(Cleaning, Polishing) -> Dirty shoes
9. Leather Customization (RE-DYE) -> Leather faded
10. Leather Alternation (Adjustment of uppers, etc widen calf of the top) -> Peeling leather/tears
"""
# Print the results
for i, label_idx in enumerate(predicted_labels):
 # Print the filename of the image and the predicted class label
 print(f"Image {image_filenames[i]} is predicted to be: {classes[label_idx]}")
 # Provide specific recommendations based on predicted classes
 if str(classes[label_idx]) == 'Broken stitches':
 print("Should be: Patch & Sewing Repair")
 elif str(classes[label_idx]) == 'Opened seam':
 print("Should be: Patch & Sewing Repair")
 elif str(classes[label_idx]) == 'Slanted heel':
 print("Should be: Heel Repair")
 elif str(classes[label_idx]) == 'Sole not flat':
 print("Should be: Hardware Repair")
 elif str(classes[label_idx]) == 'Peeling leather/tears':
 print("Should be: Leather Alternation")
 elif str(classes[label_idx]) == 'Weak cementing':
 print("Should be: Half/Full sole")
 elif str(classes[label_idx]) == 'wrinkles':
 print("Should be: Hardware Repair")
 elif str(classes[label_idx]) == 'dirty shoes':
 print("Should be: Leather Care")
 elif str(classes[label_idx]) == 'Leather Faded':
 print("Should be: Leather Customization RE-DYE")
 else:
 print("There are no specific recommendations for this class")
"""# Demo
- Demo 1: Correct to match
Structure:
1. User input
2. Image import
3. Classify damage of shoes
4. Classify type of shoes
5. Classify material of shoes
6. Comparing input and model output section
- Demo 2: Fail to match
1. User input
2. Image import
3. Classify damage of shoes
4. Classify type of shoes
5. Classify material of shoes
6. Comparing input and model output section
User input
"""
# Customer input
input_customer_type = "Dress Shoes"
input_customer_restoration = "Leather Customization RE-DYE"
# string variable for storing outcome
damage = ""
material = ""
shoes_type = ""
"""Pre-definned function to display information for backend"""
"""
print_info function:
this is just print the information to craftperson to support faster process.
"""
def print_info(control, predicted_type, predicted_damage, predicted_material, 
input_customer_type, input_customer_restoration):
 # print out the information -> match outcome
 if control == "correct":
 print("the information is correct:")
 print("Shoes type:", predicted_type)
 print("Shoes damage:", predicted_damage)
 print("Shoes material:", predicted_material)
 # print out the information -> unmatch outcome
 elif control == "wrong":
 print("The information:")
 print("The customer input:")
 print("type:" + input_customer_type)
 print("damage:" + input_customer_restoration)
 print("The model output:")
 print("Shoes type:", predicted_type)
 print("Shoes damage:", predicted_damage)
 print("Shoes material:", predicted_material)
"""## Image import"""
# Local directory containing the images
image_folder = '/content/drive/MyDrive/Colab_Notebooks/Gluu/datasets/test/Damage'
# List of image filenames in the local directory
image_filenames = [
 'Leather_faded.jpeg', # Filename of the image showing faded leather
]
images = []
for filename in image_filenames:
 img_path = os.path.join(image_folder, filename) # Construct the full path to the image file
 images.append(Image.open(img_path)) # Open the image file and append it to the images list
# Assuming image_grid is defined elsewhere in the script or imported
grid = image_grid(images, cols=3) # Create an image grid with 3 columns
grid.show() # Display the image grid using .show()
"""## Classify damage"""
# List of damage classes (labels)
classes = [
 'Broken stitches',
 'Opened seam',
 'Slanted heel',
 'Sole not flat',
 'Peeling leather/tears',
 'Weak cementing',
 'wrinkles',
 'dirty shoes',
 'Leather Faded'
]
# Process text (classes) and images using a transformer pipeline (processor)
inputs = processor(
 text=classes, # List of damage classes
 images=images, # List of images to process
 return_tensors="pt", # Return PyTorch tensors
 padding=True, # Pad inputs to the same length
 do_convert_rgb=False # Assume images are already in RGB format
)
# Pass inputs through the model to get outputs
outputs = model(inputs)
# Extract logits for image-text similarity scores
logits_per_image = outputs.logits_per_image # Tensor of similarity scores
# Apply softmax to logits to get class probabilities
probs = logits_per_image.softmax(dim=1) # Probabilities for each class label
# Get the highest scoring label (class) for each image
predicted_damage = torch.argmax(probs, dim=1) # Tensor of predicted class indices
# Convert predicted class index to damage label string
damage = str(classes[predicted_damage]) # Get the damage label for the predicted class
# Print the predicted damage label
print(damage)
"""## Classify type"""
# List of shoe types (labels)
classes = [
 'Dress Shoes',
 'Loafer',
 'Boots (Ankle)',
 'Boots (Knee High)',
 'High Heels',
 'Stilettos',
 'Sandals',
 'Runners of shoes'
]
# Process text (classes) and images using a transformer pipeline (processor)
inputs = processor(
 text=classes, # List of shoe types
 images=images, # List of images to process
 return_tensors="pt", # Return PyTorch tensors
 padding=True, # Pad inputs to the same length
 do_convert_rgb=False # Assume images are already in RGB format
)
# Pass inputs through the model to get outputs
outputs = model(inputs)
# Extract logits for image-text similarity scores
logits_per_image = outputs.logits_per_image # Tensor of similarity scores
# Apply softmax to logits to get class probabilities
probs = logits_per_image.softmax(dim=1) # Probabilities for each shoe type label
# Get the highest scoring label (shoe type) for each image
predicted_type = torch.argmax(probs, dim=1) # Tensor of predicted shoe type indices
# Convert predicted shoe type index to string label
shoes_type = str(classes[predicted_type]) # Get the shoe type label for the predicted class
# Print the predicted shoe type label
print(shoes_type)
"""## Classify material"""
# List of material classes (labels)
classes = [
 'Leather',
 'Rubber',
 'Textiles',
 'Synthetics',
 'Braided',
 'Cork',
 'Nylon',
 'Neoprene',
 'Silk',
 'Velvet',
 'Foam'
]
# Process text (classes) and images using a transformer pipeline (processor)
inputs = processor(
 text=classes, # List of material classes
 images=images, # List of images to process
 return_tensors="pt", # Return PyTorch tensors
 padding=True, # Pad inputs to the same length
 do_convert_rgb=False # Assume images are already in RGB format
)
# Pass inputs through the model to get outputs
outputs = model(inputs)
# Extract logits for image-text similarity scores
logits_per_image = outputs.logits_per_image # Tensor of similarity scores
# Apply softmax to logits to get class probabilities
probs = logits_per_image.softmax(dim=1) # Probabilities for each material label
# Get the highest scoring label (material) for each image
predicted_material = torch.argmax(probs, dim=1) # Tensor of predicted material indices
# Convert predicted material index to string label
material = str(classes[predicted_material]) # Get the material label for the predicted class
# Print the predicted material label
print(material)
"""## Comparing input and model output section
"""
# Broken Stitches
if damage == 'Broken stitches' :
 if shoes_type == input_customer_type and input_customer_restoration == "Patch & Sewing 
Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Open seam
elif damage == 'Opened seam':
 if shoes_type == input_customer_type and input_customer_restoration == "Patch & Sewing 
Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Slanted heel
elif damage == 'Slanted heel':
 if shoes_type == input_customer_type and input_customer_restoration == "Heel Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Sole not flat
elif damage == 'Sole not flat':
 if shoes_type == input_customer_type and input_customer_restoration == "Hardware Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Peeling leather/tears
elif damage == 'Peeling leather/tears' :
 if shoes_type == input_customer_type and input_customer_restoration == "Leather 
Alternation":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Weak cementing
elif damage == 'Weak cementing' :
 if shoes_type == input_customer_type and input_customer_restoration == "Half/Full sole":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Wrinkles
elif damage == 'wrinkles':
 if shoes_type == input_customer_type and input_customer_restoration == "Hardware Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Dirty shoes
elif damage == 'dirty shoes':
 if shoes_type == input_customer_type and input_customer_restoration == "Leather Care":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Leather Faded
elif damage == 'Leather Faded':
 if shoes_type == input_customer_type and input_customer_restoration == "Leather 
Customization RE-DYE":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
else:
 print("There is no recommendations")
"""# Demo 2: Unmatch
## User input
"""
# Customer input
input_customer_type = "Boost"
input_customer_restoration = "Hardware Repair"
# string variable for storing outcome
damage = ""
material = ""
shoes_type = ""
"""## Image import"""
# Local directory containing the images
image_folder = '/content/drive/MyDrive/Colab_Notebooks/Gluu/datasets/test/Damage'
# List of image filenames in the local directory
image_filenames = [
 'wrinkles.jpeg',
]
images = []
for filename in image_filenames:
 img_path = os.path.join(image_folder, filename)
 images.append(Image.open(img_path))
grid = image_grid(images, cols=3)
grid.show() # Use .show() for displaying the image grid
"""## Classify damage"""
classes = ['Broken stitches',
 'Opened seam',
 'Slanted heel',
 'Sole not flat',
 'Peeling leather/tears',
 'Weak cementing',
 'wrinkles',
 'dirty shoes',
 'Leather Faded'
 ]
inputs = processor(text=classes, images=images, return_tensors="pt", padding=True, 
do_convert_rgb=False)
outputs = model(inputs)
logits_per_image = outputs.logits_per_image # this is the image-text similarity score
probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label 
probabilities
# Get the highest scoring label for each image
predicted_damage = torch.argmax(probs, dim=1)
damage = str(classes[predicted_damage])
print(damage)
"""## Classify types"""
classes = ['Dress Shoes', 'Loafer', 'Boots (Ankle)', 'Boots (Knee High)', 'High Heels', 'Stilettos', 
'Sandals', 'Runners of shoes']
inputs = processor(text=classes, images=images, return_tensors="pt", padding=True, 
do_convert_rgb=False)
outputs = model(inputs)
logits_per_image = outputs.logits_per_image # this is the image-text similarity score
probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label 
probabilities
# Get the highest scoring label for each image
predicted_type = torch.argmax(probs, dim=1)
shoes_type = str(classes[predicted_type])
print(shoes_type)
"""## Classify material"""
classes = ['Leather',
 'Rubber',
 'Textiles',
 'Synthetics',
 'Braided',
 'Cork',
 'Nylon',
 'Neoprene',
 'Silk',
 'Velvet',
 'Foam']
inputs = processor(text=classes, images=images, return_tensors="pt", padding=True, 
do_convert_rgb=False)
outputs = model(inputs)
logits_per_image = outputs.logits_per_image # this is the image-text similarity score
probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label 
probabilities
# Get the highest scoring label for each image
predicted_material = torch.argmax(probs, dim=1)
material = str(classes[predicted_material])
print(material)
"""## Comparing input and model output section"""
# Broken Stitches
if damage == 'Broken stitches' :
 if shoes_type == input_customer_type and input_customer_restoration == "Patch & Sewing 
Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Open seam
elif damage == 'Opened seam':
 if shoes_type == input_customer_type and input_customer_restoration == "Patch & Sewing 
Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Slanted heel
elif damage == 'Slanted heel':
 if shoes_type == input_customer_type and input_customer_restoration == "Heel Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Sole not flat
elif damage == 'Sole not flat':
 if shoes_type == input_customer_type and input_customer_restoration == "Hardware Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Peeling leather/tears
elif damage == 'Peeling leather/tears' :
 if shoes_type == input_customer_type and input_customer_restoration == "Leather 
Alternation":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Weak cementing
elif damage == 'Weak cementing' :
 if shoes_type == input_customer_type and input_customer_restoration == "Half/Full sole":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Wrinkles
elif damage == 'wrinkles':
 if shoes_type == input_customer_type and input_customer_restoration == "Hardware Repair":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Dirty shoes
elif damage == 'dirty shoes':
 if shoes_type == input_customer_type and input_customer_restoration == "Leather Care":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
# Leather Faded
elif damage == 'Leather Faded':
 if shoes_type == input_customer_type and input_customer_restoration == "Leather 
Customization RE-DYE":
 print_info("correct", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
 else:
 print_info("wrong", shoes_type, damage, material, input_customer_type, 
input_customer_restoration)
else:
 print("There is no recommendations")